# Understanding Labels
- Kubernetes allows the assigning of key-value pairs called labels to objects for later use
- Maximum label length is 63 characters
- Common practise to assign one or many labels to an object at creation time
## Declaring Labels
- Can be declared imperatively with `run` command or `declaritively` in the `metadata.labels` section in the YAML manifest
- `--labels` or `-l` defines a comma-separated list of labels when creating a pod
```sh
kubectl run labeled-pod --image=nginx \
  --restart=Never --labels=tier=backend,env=dev
```
- Assigning labels to Kubernetes objects by editing the manifest requires a change to the `metadata` section
```sh
apiVersion: v1
kind: Pod
metadata:
  name: labeled-pod
  labels:
    env: dev
    tier: backend
spec:
  containers:
  - image: nginx
    name: nginx
```
## Inspecting Labels
- Common way to inspect labels via the `describe` or `get` commands
- Can use the `--show-labels` command line option to display attached labels
## Modifying Labels for a Live Object
- At any given time possible to add/remove/modify a label from an existing Kubernetes object
- Can use the following commands
	- `kubectl label pod <pod-name> <label-to-add>`
	- Editing `metadata.labels` within the YAML file
## Using Label Selectors
- Labels are meaningful when utilised with the selection feature
- A label selector uses a set of criteria to query for Kubernetes objects
### Label Selection from the command line
- Select objects by label using the `--selector` operation, or `-l` for short
- Objects can be filtered by a/an -
	- Equality-based requirement
		- Use operators `=`, `==`, `!=`, in conjunction with operators such as `AND`. **CAN NOT USE `OR`*
		- Typical expression may be like "Select all Pods with the label assignment `env=prod`"
	- Set-based requirement
		- Filter objects based on a set of values using `in`, `notin`, `exists`. `in` and `notin` work based on `OR` boolean.
		- Typical expression may be like "Select all Pods with the label key `env` and the value `prod` or `dev`"
### Label Selection in a Manifest
- Label selection in a manifest is based on the API version of the Kubernetes resource and may differ between different types
``` yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: frontend-network-policy
spec:
  podSelector:
    matchLabels:
      tier: frontend
```
- In the above YAML, network policy is applied only to those with the equality-based requirement `tier=frontend`
# Understanding Annotations
- Declared similarly to labels, represent key-value pairs for providing description metadata
- Cannot be used for querying or selecting objects
## Declaring Annotations
- `kubectl run` does not provide a command-line option for defining annotations unlike labels
- Must be initilised by the `metadata.annotation` within the YAML manifest
``` yaml
apiVersion: v1
kind: Pod
metadata:
  name: annotated-pod
  annotations:
    commit: 866a8dc
    author: 'Benjamin Muschko'
    branch: 'bm/bugfix'
spec:
  containers:
  - image: nginx
    name: nginx
```
## Inspecting Annotations
- similar to labels can use the `describe` or `get` commands
## Modifying Annotations for a Live Object
- `annotate` command is the counterpart for the `labels` command
- Can also edit the YAML manifest and `apply` the change
# Understanding Deployments
- Deployments are a Kubernetes primitive that uses labels as a foundational concept
- Can specify number of Pods running the application with the exact same setup
	- Determine number of replicas
- Ensure that failing Pods are restarted to match desired state
- Utilise the `ReplicaSet` primitive
	- Sole purpose to replicate a guaranteed number of Pods with the same configuration
## Creating Deployments
- Can be created imperatively using `create deployment`
	- `kubectl create deployment my-deploy --image=nginx:1.14.2`
- Or declaritively using the YAML manifest
	- Below - 1 replica matching on the label `app=my-deploy` under the `template` section
```YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deploy
  labels:
    app: my-deploy
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-deploy
  template:
    metadata:
      labels:
        app: my-deploy
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
```
## Listing Deployments
- `kubectl get deployments` allows you to list the current deployments for the environment
- `kubectl get replicasets` allows you to list the current replicasets for the environment
## Rendering Deployment Details
- Can inspect details using the `describe` command
## Rolling Out a New Version
- By default, a Deployment rolls out a new container image using a zero-downtime strategy by updating Pods one by one
- Every Deployment keeps a record of rollout history
	- A new version of a rollout is called a revision
	- Can retrieve detailed information of `rollout history` by providing the revision number using the `--revision` command line option
- Rolling update strategy ensures the application is always available to end users
- Can change update strategy by configuring the attribute `strategy.type`
## Rolling Back to a Previous Version
- `rollout` command can roll back to an earlier version
	- `kubectl rollout undo deployment my-deploy --to-revision=1`
- Looking at rollout history, now revision 3 exists. Following the same deployment strategy of a rolling update.
## Manually Scaling a Deployment
- Utilise the `scale` command
	- `kubectl scale deployment my-deploy --replicas=5`
- Changing the value of the `replicas` attribute for the live object and applying it
- A Deployment records scaling activities in its events which can be viewed using `describe deployment` command
## Autoscaling a Deployment
- Two autoscalers can be configured for Deployments
	- Horizontal Pod Autoscaler (HPA)
		- Standard feature of Kubernetes
		- relevant for CKAD exam
	- Vertical Pod Autoscaler (VPA)
		- Suppported by cloud provider or installed manually
- Both utilise the metrics server
### Horizontal Pod Autoscaler
- A deployment can be autoscaled using the `autoscale deployment` command
	- `kubectl autoscale deployment my-deploy --cpu-percent=70 --min=2 --max=8`
	- Can retreive information of the horizontal autoscaler using the primitive `horizontalpodautoscalers` or `hpa`
# Understanding Jobs
- A `Job` runs functionality until a specified number of completions has been reached EG.
	- One-time operations like import/export data processes 
- Upon completion of a `Job` and its Pods, objects will persist until explicitly deleted. 
## Creating and Inspecting Jobs
- To create a job can use the `create job` command
	- `kubectl create job counter --image=nginx -- /bin/sh -c 'counter=0; while [ $counter -lt 3 ]; do counter=$((counter+1)); echo "$counter"; sleep 3; done;'`
	- The above command does the following
		- Create a job that runs an iterative process
			- For each iteration a variable named `counter` is incremented
			- Finishes once `counter` reaches 3
- Can also go via the declarative route using a YAML manifest
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: counter
spec:
  template:
    spec:
      containers:
      - name: counter
        image: nginx
        command:
        - /bin/sh
        - -c
        - counter=0; while [ $counter -lt 3 ]; do counter=$((counter+1)); \
          echo "$counter"; sleep 3; done;
      restartPolicy: Never
```
## Job Operation Types
- Default behaviour of a Job is to run a workload in a pod and expects one successful completion
- Can adjust a Job by adjusting some attributes like
	- `spec.template.spec.completions`
		- Used when expect the workload to complete successfully multiple times
	- `spec.template.spec.parallelism`
		- Used to execute the workload by multiple pods in parallel 
## Restart Behaviour 
- `spec.backoffLimit`
	- Determines number of retries a Job attempts to successfully complete the workload
	- Default value is `6`, attempting 6 times before marking the Job a failure
- The job manifest needs to explicitly declare the restart policy by using the `spec.template.spec.restartPolicy` attribute
	- Default value is `Always`, other possible values can be
		- `OnFailure`
		- `Never`
### Restarting the Container on Failure
- `OnFailure`
	- Will rerun the container until successful or exhaust number of allotted retries
#### Starting a New Pod on Failure
- `Never`
	- Will create a new container until successful or exhaust number of allotted retries
# Understanding CronJobs
- A `CronJon` is a `Job` run periodically based on a schedule
	- Creates a new Pod when required to execute task
	- Defined with a cron-expression
## Creating and Inspecting Jobs
- Can use the imperative `create cronjob` command to create a new Cronjob
- `kubectl create cronjob current-date --schedule="* * * * *" --image=nginx -- /bin/sh -c 'echo "Current date: $(date)"'`
	- Above command does the following 
		- Echos current date 
		- Every minute
- Can list Cronjobs using `get cronjobs` command displaying
	- Schedule
	- Last schedule execution
	- Currently active
- Below is a declarative approach to creating a Cronjob similar to above
``` yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: current-date
spec:
  schedule: "* * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: current-date
            image: nginx
            args:
            - /bin/sh
            - -c
            - 'echo "Current date: $(date)"'
          restartPolicy: OnFailure
```
## Configuring Retained Job History
- After a CronJob has completed the Pods are not deleted automatically
	- By default, retains the last three successful pods and the last failed Pod
	- Can be adjusted using the following attributes
		- `spec.successfulJobHistoryLimit` - Number of successful Pod jobs executions to retain
		- `spec.failedJobsHistoryLimit` - Number of failed Pod Jobs executions to retain

# Samples
1. Create three Pods that use the image `nginx`. The names of the Pods should be `pod-1`, `pod-2`, and `pod-3`. Assign the label `tier=frontend` to `pod-1` and the label `tier=backend` to `pod-2` and `pod-3`. All pods should also assign the label `team=artemidis`.
```sh
kubectl run pod-1 --image=nginx --labels=tier=frontend,team=artemidis 
kubectl run pod-2 --image=nginx --labels=tier=backend,team=artemidis
kubectl run pod-3 --image=nginx --labels=tier=backend,team=artemidis
```
2. Assign the annotation with the key `deployer` to `pod-1` and `pod-3`. Use your own name as the value.
```sh
kubectl annotate pod pod-1 deployer=jordan
kubectl annotate pod pod-3 deployer=jordan
```
3. From the command line, use label selection to find all Pods with the team `artemidis` or `aircontrol` and that are considered a backend service.
```sh
kubectl get po -l 'team in (artemidis, aircontrol), tier in (backend)'
```
4. Create a new Deployment named `server-deployment`. The Deployment should control two replicas using the image `grand-server:1.4.6`.
```sh
kubectl create deployment server-deployment --image=grand-server:1.4.6 --replicas=2
```
5. Inspect the Deployment and find out the root cause for its failure.
```sh
kubectl get events
Warning   Failed                    pod/server-deployment-545bb58c68-nhgnn    Failed to pull image "grand-server:1.4.6": rpc error: code = Unknown desc = Error response from daemon: pull access denied for grand-server, repository does not exist or may require 'docker login': denied: requested access to the resource is denied

```
6. Fix the issue by assigning the image `nginx` instead. Inspect the rollout history. How many revisions would you expect to see?
```sh
kubectl rollout history deployment server-deployment
``` 
7. Create a new CronJob named `google-ping`. When executed, the Job should run a `curl` command for `google.com`. Pick an appropriate image. The execution should occur every two minutes.
```sh
kubectl create cj google-ping --image=busybox --schedule="*/2 * * * *" -o yaml --dry-run=client -- /bin/sh -c 'curl google.com'
kubectl apply -f cj.yaml
```
8. Tail the logs of the CronJob at runtime. Check the command-line options of the relevant command or consult the Kubernetes documentation.
```sh
kubectl logs <pod> -f
```
9. Reconfigure the CronJob to retain a history of seven executions.
```yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  creationTimestamp: null
  name: google-ping
spec:
  successfulJobsHistoryLimit: 7
  jobTemplate:
    metadata:
      creationTimestamp: null
      name: google-ping
    spec:
      template:
        metadata:
          creationTimestamp: null
        spec:
          containers:
          - command:
            - /bin/sh
            - -c
            - wget  google.com
            image: busybox
            name: google-ping
            resources: {}
          restartPolicy: OnFailure
  schedule: '*/2 * * * *'
status: {}
```
10. Reconfigure the CronJob to disallow a new execution if the current execution is still running. Consult the Kubernetes documentation for more information.
```yaml
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  creationTimestamp: null
  name: google-ping
spec:
  successfulJobsHistoryLimit: 7
  concurrencyPolicy: Forbid
  jobTemplate:
    metadata:
      creationTimestamp: null
      name: google-ping
    spec:
      template:
        metadata:
          creationTimestamp: null
        spec:
          containers:
          - command:
            - /bin/sh
            - -c
            - wget  google.com
            image: busybox
            name: google-ping
            resources: {}
          restartPolicy: OnFailure
  schedule: '*/2 * * * *'
status: {}
```